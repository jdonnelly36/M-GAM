{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in our accuracies for FICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfs = []\n",
    "for s_iter in range(50):\n",
    "    #df = pd.read_csv(f'./parallelized_results/baselines_2024-01-28_iter_{s_iter}_MICE_imp_10_imp.csv')\n",
    "    df = pd.read_csv(f'./parallelized_results/baselines_2024-02-25_iter_{s_iter}_10_imp_all_50_max_coef.csv')\n",
    "    dfs.append(df)\n",
    "combined_acc_df = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfs = []\n",
    "for s_iter in range(50):\n",
    "    df = pd.read_csv(f'./parallelized_results/baselines_2024-01-31_iter_{s_iter}_10_imp_all.csv')\n",
    "    dfs.append(df)\n",
    "combined_acc_df = pd.concat(dfs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfs = []\n",
    "for ds_name in ['PHARYNGITIS']:\n",
    "    for imputation_method in ['MIWAE']:\n",
    "        for s_iter in range(120):\n",
    "            try:\n",
    "                #df = pd.read_csv(f'./parallelized_results/baselines_2024-02_01_iter_{s_iter}_10_imp_all.csv')\n",
    "                df = pd.read_csv(f'./parallelized_results/baselines_iter_{s_iter}_{ds_name}_{imputation_method}.csv')\n",
    "                dfs.append(df)\n",
    "            except:\n",
    "                continue\n",
    "combined_acc_df = pd.concat(dfs, axis=0)\n",
    "\n",
    "target_imp = 'MIWAE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (combined_acc_df['num_imputations'] == 10) & \\\n",
    "        (combined_acc_df['missingness_handling'] == target_imp)\n",
    "cur_acc_df = combined_acc_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smim_tag(row):\n",
    "    if row['use_smim']:\n",
    "        return row['model_type'] + ' (SMIM)'\n",
    "    else:\n",
    "        return row['model_type'] + ' (No SMIM)'\n",
    "cur_acc_df['model_type'] = cur_acc_df.apply(get_smim_tag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_acc_df = cur_acc_df.groupby(['model_type', 'dataset', 'holdout_set', 'metric', 'missingness_handling']).mean().reset_index()\n",
    "cur_acc_df['model_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we have a distinct entry for each val set for our gams,\n",
    "# we need to take the average of each value along val sets\n",
    "cur_acc_df = cur_acc_df.groupby(['model_type', 'dataset', 'holdout_set', 'metric', 'missingness_handling']).mean().reset_index()\n",
    "\n",
    "# Now lets filter down to grab just AUC for BRECA, ACC for FICO\n",
    "#cur_acc_df = pd.concat([\n",
    "    #cur_acc_df[(cur_acc_df['dataset'] == 'FICO') & (cur_acc_df['metric'] == 'acc')],\n",
    "    #cur_acc_df[(cur_acc_df['dataset'] == 'BREAST_CANCER') & (cur_acc_df['metric'] == 'auc')]\n",
    "#], axis=0)\n",
    "cur_acc_df = cur_acc_df[cur_acc_df['metric'] == 'auc']\n",
    "\n",
    "\n",
    "cur_acc_df = cur_acc_df[cur_acc_df['model_type'] != 'GAM_no_missing (SMIM)']\n",
    "\n",
    "cur_acc_df['Model Type'] = cur_acc_df['model_type']\n",
    "cur_acc_df.loc[cur_acc_df['Model Type'] == 'GAM_imputation (SMIM)', 'Model Type'] = 'GAM (Imputation)'\n",
    "cur_acc_df.loc[cur_acc_df['Model Type'] == 'GAM_ind (SMIM)', 'Model Type'] = 'GAM (Indicators)'\n",
    "cur_acc_df.loc[cur_acc_df['Model Type'] == 'GAM_aug (SMIM)', 'Model Type'] = 'GAM (Interactions)'\n",
    "\n",
    "cur_acc_df.loc[cur_acc_df['dataset'] == 'BREAST_CANCER', 'dataset'] = 'Breast Cancer'\n",
    "\n",
    "cur_acc_df = cur_acc_df.sort_values('Model Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "#for dataset in acc_res['dataset'].unique():\n",
    "#mask = acc_res['dataset'] == dataset\n",
    "sns.set(font_scale=2.0)\n",
    "figure(figsize=(6, 8), dpi=80)\n",
    "ax = sns.boxplot(\n",
    "    cur_acc_df, hue='Model Type', y='metric_value_test', x='dataset'\n",
    ")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(0.0, 2.0), ncol=2)\n",
    "plt.xlabel('')\n",
    "#plt.ylim((0.75, 0.85))\n",
    "#plt.title(dataset)\n",
    "plt.ylabel('Test ACC')\n",
    "plt.xticks(rotation=0, ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning to consider alternative imputation strategies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in our timing data for each imputation method (over 10 imputations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_list = [\n",
    "    pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-28_all_BREAST_CANCER_GAIN.csv'),\n",
    "    pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-28_all_FICO_GAIN.csv'),\n",
    "    #pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-28_all_FICO_MissForest.csv'),\n",
    "    pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-29_all_FICO_MIWAE.csv'),\n",
    "]\n",
    "for dataset in ['BREAST_CANCER', 'FICO']:\n",
    "    try:\n",
    "        df_list.append(pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-27_all_{dataset}.csv'))\n",
    "    except:\n",
    "        df_list.append(pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-27_all_{dataset}.csv'))\n",
    "base_timing_df = pd.concat(df_list, axis=0)\n",
    "base_timing_df['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_timing_df = base_timing_df[base_timing_df['m'] < 10]\n",
    "base_timing_df['imputation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = base_timing_df.groupby(['dataset', 'holdout_set', 'imputation', 'validation_set']).sum()\n",
    "tmp_df = tmp_df.groupby(['dataset', 'holdout_set', 'imputation']).mean()\n",
    "\n",
    "# For MICE, time_overall has the total time, and all the others are 0;\n",
    "# The opposite holds for the other methods\n",
    "tmp_df['time_overall'] = tmp_df['time_overall'] + tmp_df['time_for_test'] \\\n",
    "    + tmp_df['time_for_val'] + tmp_df['time_for_train'] + tmp_df['time_to_fit'] \n",
    "tmp_df = tmp_df.reset_index()\n",
    "\n",
    "mask = (combined_acc_df['num_imputations'] == 10)\\\n",
    "     & (combined_acc_df['missingness_handling'] != 'GAIN')\\\n",
    "     & (combined_acc_df['metric'] == 'auc') & (combined_acc_df['dataset'] == 'BREAST_CANCER')\n",
    "     #& (combined_acc_df['metric'] == 'acc') & (combined_acc_df['dataset'] == 'FICO')\n",
    "acc_df = combined_acc_df[mask]\n",
    "tmp_df_acc = acc_df.groupby(['dataset', 'holdout_set', 'model_type', 'missingness_handling']).mean().reset_index()\n",
    "tmp_df_acc['imputation'] = tmp_df_acc['missingness_handling']\n",
    "\n",
    "merged_df = tmp_df_acc.merge(tmp_df, on=['holdout_set', 'imputation', 'dataset'], how='inner')\n",
    "\n",
    "# Because we only want models that rely on imputations\n",
    "merged_df = merged_df[(merged_df['model_type'] != 'GAM_ind') & (merged_df['model_type'] != 'GAM_aug') & (merged_df['model_type'] != 'GAM_no_missing')]\n",
    "merged_df['time_overall'] = merged_df['time_overall'] + merged_df['mean_fit_time'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Model Type'] = merged_df['model_type']\n",
    "merged_df['Imputation'] = merged_df['imputation']\n",
    "mask = merged_df['Model Type'] == 'GAM_imputation'\n",
    "merged_df.loc[mask, 'Model Type'] = 'GAM (Imputation)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "#stacked_time_df_fico = stacked_time_df[stacked_time_df['data_type'] != 'BREAST_CANCER']\n",
    "color_pal = sns.color_palette()\n",
    "'''g = sns.FacetGrid(\n",
    "    merged_df[merged_df['dataset'] == 'FICO'], \n",
    "    col=\"imputation\", \n",
    "    col_wrap=2, \n",
    "    height=6, \n",
    "    sharey=True,\n",
    "    sharex=False)\n",
    "g.map_dataframe(sns.scatterplot,\n",
    "    x='time_overall',\n",
    "    y='metric_value_test',\n",
    "    hue='model_type',\n",
    "    #label=\"Model Fit Time\",\n",
    "    #errorbar='se'\n",
    "    #hue='model'\n",
    ")\n",
    "g.add_legend(loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=2)\n",
    "g.set_xlabels('')'''\n",
    "\n",
    "sns.set(font_scale=2.0)\n",
    "g = sns.scatterplot(\n",
    "    data=merged_df,\n",
    "    x='time_overall',\n",
    "    y='metric_value_test',\n",
    "    hue='Imputation',\n",
    "    style='Model Type'\n",
    "    #label=\"Model Fit Time\",\n",
    "    #errorbar='se'\n",
    "    #hue='model'\n",
    ")\n",
    "#g.set_xticklabels([m for m in stacked_time_df_fico['model_nice'].unique()], rotation=45, ha='right')\n",
    "g.set_xlabel('Runtime (Seconds)')\n",
    "g.set_ylabel('Test AUC')\n",
    "g.set_title('FICO')\n",
    "#g.legend(loc='upper center', bbox_to_anchor=(0.5, 1.55), ncol=2)\n",
    "g.legend(loc='upper center', bbox_to_anchor=(1.5, 0.9), ncol=1)\n",
    "#g.set_ylabel('Time (Seconds)')\n",
    "#plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=2)\n",
    "\n",
    "#for ax, title in zip(g.axes.flat, ['FICO (1,883 Samples)', 'FICO (3,765 Samples)', 'FICO (5,648 Samples)', \n",
    "#                                    'FICO (7,530 Samples)']):\n",
    "#    ax.set_title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data for different numbers of imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_acc_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in model fitting data\n",
    "'''import pandas as pd\n",
    "df_list = []\n",
    "for n_imps in [1, 5, 10, 20, 30]:\n",
    "    df_acc = pd.read_csv(f'full_baseline_results_many_clf_tmp_multi_2024-01-28_10_holdouts_FICO_{n_imps}_imp.csv')\n",
    "    df_acc = df_acc[df_acc['metric'] == 'acc']\n",
    "    \n",
    "    df_list.append(df_acc)\n",
    "df_acc = pd.concat(df_list, axis=0)\n",
    "df_acc['model_type'].value_counts()'''\n",
    "\n",
    "df_acc = combined_acc_df[(combined_acc_df['missingness_handling'] == 'MICE') \\\n",
    "                        & (combined_acc_df['dataset'] == 'FICO')\\\n",
    "                        & (combined_acc_df['metric'] == 'acc')\\\n",
    "                        & (combined_acc_df['model_type'] != 'GAM_aug')\\\n",
    "                        & (combined_acc_df['model_type'] != 'GAM_ind')\\\n",
    "                        & (combined_acc_df['model_type'] != 'GAM_no_missing')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_list = []\n",
    "for dataset in ['FICO']:\n",
    "    try:\n",
    "        df_list.append(pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-27_all_{dataset}.csv'))\n",
    "    except:\n",
    "        df_list.append(pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-27_all_{dataset}.csv'))\n",
    "base_timing_df = pd.concat(df_list, axis=0)\n",
    "base_timing_df['dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_counts_to_consider = [1, 5, 10, 20, 30]\n",
    "df_list = []\n",
    "for i in imp_counts_to_consider:\n",
    "    cur_acc_df = df_acc[df_acc['num_imputations'] == i].reset_index()\n",
    "    cur_acc_df = cur_acc_df[cur_acc_df['model_type'] != 'GAM_ind']\n",
    "    cur_acc_df = cur_acc_df[cur_acc_df['model_type'] != 'GAM_aug']\n",
    "\n",
    "    cur_acc_df['Model Type'] = cur_acc_df['model_type']\n",
    "    cur_acc_df.loc[cur_acc_df['Model Type'] == 'GAM_imputation', 'Model Type'] = 'GAM (Imputation)'\n",
    "\n",
    "    tmp_df = base_timing_df[base_timing_df['m'] < i].groupby(['dataset', 'holdout_set', 'validation_set']).sum()\n",
    "    tmp_df = tmp_df.groupby(['dataset', 'holdout_set']).mean().add_suffix('_agg').reset_index()\n",
    "    #tmp_df = base_timing_df[base_timing_df['m'] < i].groupby(['dataset', 'holdout_set']).sum().add_suffix('_agg').reset_index()\n",
    "    #tmp_df = tmp_df.groupby('dataset').mean().reset_index()\n",
    "    tmp_df['num_imputations'] = i\n",
    "\n",
    "    tmp_df = tmp_df.merge(cur_acc_df, on=['num_imputations', 'holdout_set'], how='outer')\n",
    "\n",
    "    df_list.append(tmp_df)\n",
    "df_agg = pd.concat(df_list, axis=0)\n",
    "df_agg['time_overall'] = df_agg['time_overall_agg'] + df_agg['mean_fit_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(font_scale=1.1)\n",
    "#df_agg['Model Type'] = df_agg['model_type']\n",
    "df_agg['Number of Imputations'] = df_agg['num_imputations']\n",
    "g = sns.scatterplot(\n",
    "    data=df_agg,\n",
    "    x='time_overall',\n",
    "    y='metric_value_test',\n",
    "    hue='Number of Imputations',\n",
    "    style='Model Type',\n",
    ")\n",
    "g.set_xlabel('Runtime (Seconds)')\n",
    "g.set_ylabel('Test Accuracy')\n",
    "g.legend(loc='upper center', bbox_to_anchor=(1.3, 1.0), ncol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting runtime for different subsets of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in model fitting data\n",
    "import pandas as pd\n",
    "dataset_of_interest = 'FICO'\n",
    "imputations_of_interest = ['Mean', 'MICE']\n",
    "#base_timing_df = pd.concat([\n",
    "#    pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-27_all_{dataset_of_interest}.csv'),\n",
    "#    pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-27_all_{dataset_of_interest}_0.25.csv'),\n",
    "#    pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-27_all_{dataset_of_interest}_0.5.csv'),\n",
    "#    pd.read_csv(f'../../handling_missing_data/timing_stats_10_val_2024-01-27_all_{dataset_of_interest}_0.75.csv')\n",
    "#], axis=0)\n",
    "dfs = []\n",
    "for ds_name in [f'{dataset_of_interest}', f'{dataset_of_interest}_0.25']:#, f'{dataset_of_interest}_0.5', f'{dataset_of_interest}_0.75']:\n",
    "    for imputation_method in imputations_of_interest:\n",
    "        for s_iter in range(120):\n",
    "            #df = pd.read_csv(f'./parallelized_results/baselines_2024-02_01_iter_{s_iter}_10_imp_all.csv')\n",
    "            df = pd.read_csv(f'./parallelized_results/baselines_iter_{s_iter}_{ds_name}_{imputation_method}.csv')\n",
    "            dfs.append(df)\n",
    "combined_acc_df = pd.concat(dfs, axis=0)\n",
    "\n",
    "df_list = []\n",
    "for ds_name in [dataset_of_interest]:\n",
    "    for imputation_method in imputations_of_interest:\n",
    "        for subsample in ['', '_0.25', '_0.5', '_0.75']:\n",
    "            df_list.append(pd.read_csv(f'../../handling_missing_data/timing_stats_{ds_name}{subsample}_{imputation_method}_5_3.csv'))\n",
    "base_timing_df = pd.concat(df_list, axis=0)\n",
    "\n",
    "base_timing_df = base_timing_df[(base_timing_df['m'] < 10) & (base_timing_df['imputation'].isin(imputations_of_interest))]\n",
    "\n",
    "mask = (combined_acc_df['num_imputations'] == 10)\n",
    "acc_df = combined_acc_df[mask]\n",
    "if dataset_of_interest == 'BREAST_CANCER':\n",
    "    acc_df = acc_df[acc_df['metric'] == 'auc']\n",
    "else:\n",
    "    acc_df = acc_df[acc_df['metric'] == 'acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_timing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_timing_df['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.groupby(['dataset', 'model_type']).mean()['mean_fit_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_timing_df = base_timing_df.groupby(['holdout_set', 'dataset', 'validation_set', 'imputation']).sum().reset_index()\n",
    "#base_timing_df = base_timing_df.groupby(['holdout_set', 'dataset']).mean().reset_index()\n",
    "#base_timing_df\n",
    "#base_timing_df['holdout_set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = acc_df.groupby(['dataset', 'holdout_set', 'model_type']).mean().reset_index()#['holdout_set'].value_counts()\n",
    "\n",
    "merged_df = base_timing_df.merge(acc_df, how='inner', on=['dataset','holdout_set'])\n",
    "\n",
    "mask = (merged_df['model_type'] != 'GAM_ind') & (merged_df['model_type'] != 'GAM_aug')\n",
    "merged_df['impute_time'] = merged_df['time_overall']\n",
    "merged_df['overall_time'] = 0\n",
    "merged_df.loc[mask, 'overall_time'] = merged_df.loc[mask, 'impute_time'] + merged_df.loc[mask, 'mean_fit_time']\n",
    "merged_df.loc[~mask, 'overall_time'] = merged_df.loc[~mask,'mean_fit_time']\n",
    "merged_df.loc[~mask, 'impute_time'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[merged_df['model_type'] != 'GAM_no_missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = merged_df['model_type'] == 'GAM_aug'\n",
    "merged_df.loc[mask, 'model_type'] = 'GAM (Interactions)'\n",
    "mask = merged_df['model_type'] == 'GAM_ind'\n",
    "merged_df.loc[mask, 'model_type'] = 'GAM (Indicators)'\n",
    "mask = merged_df['model_type'] == 'GAM_imputation'\n",
    "merged_df.loc[mask, 'model_type'] = 'GAM (Imputation)'\n",
    "\n",
    "\"\"\"mask = merged_df['dataset'] == 'FICO'\n",
    "merged_df.loc[mask, 'dataset'] = 'FICO (7,530 Samples)'\n",
    "mask = merged_df['dataset'] == 'FICO_0.25'\n",
    "merged_df.loc[mask, 'dataset'] = 'FICO (1,883 Samples)'\n",
    "mask = merged_df['dataset'] == 'FICO_0.5'\n",
    "merged_df.loc[mask, 'dataset'] = 'FICO (3,765 Samples)'\n",
    "mask = merged_df['dataset'] == 'FICO_0.75'\n",
    "merged_df.loc[mask, 'dataset'] = 'FICO (5,648 Samples)'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.groupby('model_type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.sort_values('model_type')\n",
    "\"\"\"if dataset_of_interest == 'FICO':\n",
    "    merged_df = pd.concat([\n",
    "        merged_df[merged_df['dataset'] == 'FICO (1,883 Samples)'],\n",
    "        merged_df[merged_df['dataset'] == 'FICO (3,765 Samples)'],\n",
    "        merged_df[merged_df['dataset'] == 'FICO (5,648 Samples)'],\n",
    "        merged_df[merged_df['dataset'] == 'FICO (7,530 Samples)'],\n",
    "    ], axis=0)\n",
    "else:\n",
    "    merged_df = pd.concat([\n",
    "        merged_df[merged_df['dataset'] == 'BREAST_CANCER_0.25'],\n",
    "        merged_df[merged_df['dataset'] == 'BREAST_CANCER_0.5'],\n",
    "        merged_df[merged_df['dataset'] == 'BREAST_CANCER_0.75'],\n",
    "        merged_df[merged_df['dataset'] == 'BREAST_CANCER'],\n",
    "    ], axis=0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_pal = sns.color_palette()\n",
    "sns.set(font_scale=1.3)\n",
    "g = sns.FacetGrid(\n",
    "    merged_df, \n",
    "    col=\"dataset\", \n",
    "    col_wrap=2, \n",
    "    height=4, \n",
    "    sharey=True)\n",
    "g.map_dataframe(sns.barplot,\n",
    "    x='model_type',\n",
    "    y='overall_time',\n",
    "    hue='imputation',\n",
    "    color=color_pal[1],\n",
    "    #label=\"Model Fit Time\"\n",
    "    #hue='model'\n",
    ")\n",
    "g.map_dataframe(sns.barplot,\n",
    "    x='model_type',\n",
    "    y='impute_time',\n",
    "    hue='imputation',\n",
    "    color=color_pal[0],\n",
    "    #label=\"Imputation Time\"\n",
    "    #hue='model'\n",
    ")\n",
    "g.set_xticklabels([m for m in merged_df['model_type'].unique()],\n",
    "                    rotation=45, ha='right')\n",
    "\n",
    "for tick_in, tick_label in enumerate(g.axes[-2].xaxis.get_ticklabels()):\n",
    "    if merged_df['model_type'].unique()[tick_in] in ['GAM (Interactions)', 'GAM (Indicators)']:\n",
    "        #tick_label.set_color(\"red\")\n",
    "        tick_label.set_font({'weight': 'bold'})\n",
    "    else:\n",
    "        tick_label.set_color(\"black\")\n",
    "\n",
    "for tick_in, tick_label in enumerate(g.axes[-1].xaxis.get_ticklabels()):\n",
    "    if merged_df['model_type'].unique()[tick_in] in ['GAM (Interactions)', 'GAM (Indicators)']:\n",
    "        #tick_label.set_color(\"red\")\n",
    "        tick_label.set_font({'weight': 'bold'})\n",
    "    else:\n",
    "        tick_label.set_color(\"black\")\n",
    "    \n",
    "g.set_xlabels('')\n",
    "g.set_ylabels('Time (Seconds)')\n",
    "\n",
    "if dataset_of_interest == 'FICO':\n",
    "    for ax, title in zip(g.axes.flat, ['FICO \\n(2,615 Samples)', 'FICO \\n(5,230 Samples)', \n",
    "                                        'FICO \\n(7,844 Samples)', 'FICO \\n(10,459 Samples)']):\n",
    "        ax.set_title(title)\n",
    "elif dataset_of_interest == 'BREAST_CANCER':\n",
    "    for ax, title in zip(g.axes.flat, ['Breast Cancer \\n(439 Samples)', 'Breast Cancer \\n(878 Samples)', \n",
    "                                        'Breast Cancer \\n(1,317 Samples)', 'Breast Cancer \\n(1,756 Samples)']):\n",
    "        ax.set_title(title)\n",
    "plt.tight_layout()\n",
    "g.add_legend()\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(0.25, 1.05), ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "missing_data",
   "language": "python",
   "name": "missing_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
