{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the baseline accuracy figures\n",
    "\n",
    "### Figure 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfs = []\n",
    "target_imp = ['MICE']\n",
    "for ds_name in ['BREAST_CANCER', 'MIMIC', 'PHARYNGITIS', 'FICO']:#, 'CKD', 'HEART_DISEASE']:\n",
    "    for imputation_method in target_imp:\n",
    "        for s_iter in range(120):\n",
    "            try:\n",
    "                #df = pd.read_csv(f'./parallelized_results/baselines_2024-02_01_iter_{s_iter}_10_imp_all.csv')\n",
    "                df = pd.read_csv(f'./parallelized_results/baselines_iter_{s_iter}_{ds_name}_{imputation_method}.csv')\n",
    "                dfs.append(df)\n",
    "            except:\n",
    "                print(f\"WARNING: Skipping iteration {s_iter}\")\n",
    "                continue\n",
    "combined_acc_df = pd.concat(dfs, axis=0)\n",
    "\n",
    "target_metric = 'acc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (combined_acc_df['num_imputations'] == 10) & \\\n",
    "        (combined_acc_df['missingness_handling'].isin(target_imp))\n",
    "cur_acc_df = combined_acc_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smim_tag(row):\n",
    "    if row['use_smim']:\n",
    "        return row['model_type'] + ' (SMIM)'\n",
    "    else:\n",
    "        return row['model_type'] + ' (No SMIM)'\n",
    "cur_acc_df['model_type'] = cur_acc_df.apply(get_smim_tag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we have a distinct entry for each val set for our gams,\n",
    "# we need to take the average of each value along val sets\n",
    "cur_acc_df = cur_acc_df.groupby(['model_type', 'dataset', 'holdout_set', 'metric', 'missingness_handling']).mean().reset_index()\n",
    "cur_acc_df['model_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets filter down to grab just AUC for BRECA, ACC for FICO\n",
    "#cur_acc_df = pd.concat([\n",
    "    #cur_acc_df[(cur_acc_df['dataset'] == 'FICO') & (cur_acc_df['metric'] == 'acc')],\n",
    "    #cur_acc_df[(cur_acc_df['dataset'] == 'BREAST_CANCER') & (cur_acc_df['metric'] == 'auc')]\n",
    "#], axis=0)\n",
    "cur_acc_df = cur_acc_df[cur_acc_df['metric'] == target_metric]\n",
    "\n",
    "\n",
    "cur_acc_df = cur_acc_df[cur_acc_df['model_type'] != 'GAM_no_missing (SMIM)']\n",
    "\n",
    "cur_acc_df['Model Type'] = cur_acc_df['model_type']\n",
    "cur_acc_df.loc[cur_acc_df['Model Type'] == 'GAM_imputation (SMIM)', 'Model Type'] = 'M-GAM (Imputation)'\n",
    "cur_acc_df.loc[cur_acc_df['Model Type'] == 'GAM_ind (SMIM)', 'Model Type'] = 'M-GAM (Indicators Only)'\n",
    "cur_acc_df.loc[cur_acc_df['Model Type'] == 'GAM_aug (SMIM)', 'Model Type'] = 'M-GAM (w/ Interactions)'\n",
    "\n",
    "cur_acc_df.loc[cur_acc_df['dataset'] == 'BREAST_CANCER', 'dataset'] = 'Breast Cancer'\n",
    "cur_acc_df.loc[cur_acc_df['dataset'] == 'HEART_DISEASE', 'dataset'] = 'Heart Disease'\n",
    "cur_acc_df.loc[cur_acc_df['dataset'] == 'PHARYNGITIS', 'dataset'] = 'Pharyngitis'\n",
    "cur_acc_df.loc[cur_acc_df['dataset'] == 'ADULT', 'dataset'] = 'Adult'\n",
    "\n",
    "cur_acc_df = cur_acc_df.sort_values('Model Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "for d_ind, dataset in enumerate(cur_acc_df['dataset'].unique()):\n",
    "    mask = cur_acc_df['dataset'] == dataset\n",
    "    tmp_cur_acc_df = cur_acc_df[mask]\n",
    "    sns.set(font_scale=2.5)\n",
    "    figure(figsize=(6, 8), dpi=80)\n",
    "    ax = sns.boxplot(\n",
    "        tmp_cur_acc_df, hue='Model Type', y='metric_value_test'\n",
    "    )\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(0.0, 2.0), ncol=2)\n",
    "    plt.xlabel('')\n",
    "    if dataset == \"MIMIC\":\n",
    "        plt.ylim((0.86, 0.94))\n",
    "    if dataset == \"PHARYNGITIS\":\n",
    "        plt.title(\"Pharyngitis\")\n",
    "    else:\n",
    "        plt.title(dataset)\n",
    "    plt.ylabel(f'Test {target_metric.upper()}')\n",
    "    plt.xticks(rotation=0, ha='center')\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "cur_acc_df = cur_acc_df.sort_values('dataset')\n",
    "cur_acc_df['Test Accuracy'] = cur_acc_df['metric_value_test']\n",
    "mgam_methods = ['M-GAM (Indicators Only)', 'M-GAM (w/ Interactions)']\n",
    "ordered_list = [m for m in cur_acc_df['Model Type'].unique() if m not in mgam_methods]\n",
    "ordered_list.sort()\n",
    "ordered_list = mgam_methods + ordered_list\n",
    "print(ordered_list)\n",
    "cur_acc_df = pd.concat(\n",
    "    [cur_acc_df[cur_acc_df['Model Type'] == m] for m in ordered_list], axis=0\n",
    ")\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    cur_acc_df,\n",
    "    #row='dataset',\n",
    "    #col='missingness_handling',\n",
    "    col='dataset',\n",
    "    #col_wrap=4, \n",
    "    # aspect=0.8,\n",
    "    height=7, \n",
    "    #sharey=\"row\",\n",
    "    sharey=False\n",
    "    #margin_titles=True\n",
    ")\n",
    "#figure(figsize=(6, 8), dpi=80)\n",
    "g.map_dataframe(\n",
    "    sns.boxplot,\n",
    "    hue='Model Type',\n",
    "    palette=sns.color_palette('Spectral', n_colors=14),\n",
    "    y='Test Accuracy'\n",
    ")\n",
    "g.set_titles(\n",
    "    row_template='{row_name}',\n",
    "    col_template='{col_name}',\n",
    ")\n",
    "'''ax = sns.boxplot(\n",
    "    tmp_cur_acc_df, hue='Model Type', y='metric_value_test'\n",
    ")'''\n",
    "g.add_legend()\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(0.08, 1.4), ncol=3)\n",
    "\n",
    "for text in g.legend.texts:\n",
    "    if \"GAM\" in text.get_text():\n",
    "        text.set_fontweight(\"bold\")\n",
    "        text.set_color(\"red\")\n",
    "\n",
    "#plt.xticks(rotation=0, ha='center')\n",
    "sns.set(font_scale=2.3)\n",
    "for ind, ax in enumerate(g.axes.flat):\n",
    "    if ind == 2:\n",
    "        ax.set_ylim(0.86, 0.94)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Appendix Fig 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfs = []\n",
    "target_imp = ['MICE', 'Mean', 'MIWAE', 'MissForest']\n",
    "for ds_name in ['BREAST_CANCER', 'MIMIC', 'PHARYNGITIS', 'FICO', 'CKD', 'HEART_DISEASE']:\n",
    "    for imputation_method in target_imp:\n",
    "        for s_iter in range(120):\n",
    "            try:\n",
    "                #df = pd.read_csv(f'./parallelized_results/baselines_2024-02_01_iter_{s_iter}_10_imp_all.csv')\n",
    "                df = pd.read_csv(f'./parallelized_results/baselines_iter_{s_iter}_{ds_name}_{imputation_method}.csv')\n",
    "                dfs.append(df)\n",
    "            except:\n",
    "                print(f\"WARNING: Skipping iteration {s_iter}\")\n",
    "                continue\n",
    "combined_acc_df = pd.concat(dfs, axis=0)\n",
    "\n",
    "target_metric = 'acc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (combined_acc_df['num_imputations'] == 10) & \\\n",
    "        (combined_acc_df['missingness_handling'].isin(target_imp))\n",
    "cur_acc_df = combined_acc_df[mask]\n",
    "\n",
    "def get_smim_tag(row):\n",
    "    if row['use_smim']:\n",
    "        return row['model_type'] + ' (SMIM)'\n",
    "    else:\n",
    "        return row['model_type'] + ' (No SMIM)'\n",
    "cur_acc_df['model_type'] = cur_acc_df.apply(get_smim_tag, axis=1)\n",
    "\n",
    "# Because we have a distinct entry for each val set for our gams,\n",
    "# we need to take the average of each value along val sets\n",
    "cur_acc_df = cur_acc_df.groupby(['model_type', 'dataset', 'holdout_set', 'metric', 'missingness_handling']).mean().reset_index()\n",
    "cur_acc_df['model_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets filter down to grab just AUC for BRECA, ACC for FICO\n",
    "#cur_acc_df = pd.concat([\n",
    "    #cur_acc_df[(cur_acc_df['dataset'] == 'FICO') & (cur_acc_df['metric'] == 'acc')],\n",
    "    #cur_acc_df[(cur_acc_df['dataset'] == 'BREAST_CANCER') & (cur_acc_df['metric'] == 'auc')]\n",
    "#], axis=0)\n",
    "cur_acc_df = cur_acc_df[cur_acc_df['metric'] == target_metric]\n",
    "\n",
    "\n",
    "cur_acc_df = cur_acc_df[cur_acc_df['model_type'] != 'GAM_no_missing (SMIM)']\n",
    "\n",
    "cur_acc_df['Model Type'] = cur_acc_df['model_type']\n",
    "cur_acc_df.loc[cur_acc_df['Model Type'] == 'GAM_imputation (SMIM)', 'Model Type'] = 'M-GAM (Imputation)'\n",
    "cur_acc_df.loc[cur_acc_df['Model Type'] == 'GAM_ind (SMIM)', 'Model Type'] = 'M-GAM (Indicators Only)'\n",
    "cur_acc_df.loc[cur_acc_df['Model Type'] == 'GAM_aug (SMIM)', 'Model Type'] = 'M-GAM (w/ Interactions)'\n",
    "\n",
    "cur_acc_df.loc[cur_acc_df['dataset'] == 'BREAST_CANCER', 'dataset'] = 'Breast Cancer'\n",
    "cur_acc_df.loc[cur_acc_df['dataset'] == 'HEART_DISEASE', 'dataset'] = 'Heart Disease'\n",
    "cur_acc_df.loc[cur_acc_df['dataset'] == 'PHARYNGITIS', 'dataset'] = 'Pharyngitis'\n",
    "cur_acc_df.loc[cur_acc_df['dataset'] == 'ADULT', 'dataset'] = 'Adult'\n",
    "\n",
    "cur_acc_df = cur_acc_df.sort_values('Model Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "cur_acc_df['Test Accuracy'] = cur_acc_df['metric_value_test']\n",
    "mgam_methods = ['M-GAM (Indicators Only)', 'M-GAM (w/ Interactions)']\n",
    "ordered_list = [m for m in cur_acc_df['Model Type'].unique() if m not in mgam_methods]\n",
    "ordered_list.sort()\n",
    "ordered_list = mgam_methods + ordered_list\n",
    "print(ordered_list)\n",
    "cur_acc_df = pd.concat(\n",
    "    [cur_acc_df[cur_acc_df['Model Type'] == m] for m in ordered_list], axis=0\n",
    ")\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    cur_acc_df,\n",
    "    row='dataset',\n",
    "    row_order=['Breast Cancer', 'CKD', 'FICO', 'Heart Disease', 'Pharyngitis', 'MIMIC'],\n",
    "    col='missingness_handling',\n",
    "    #col_wrap=4, \n",
    "    height=7, \n",
    "    sharey=\"row\",\n",
    "    #sharey=False,\n",
    "    margin_titles=True\n",
    ")\n",
    "#figure(figsize=(6, 8), dpi=80)\n",
    "g.map_dataframe(\n",
    "    sns.boxplot,\n",
    "    hue='Model Type',\n",
    "    palette=sns.color_palette('Spectral', n_colors=14),\n",
    "    y='Test Accuracy'\n",
    ")\n",
    "g.set_titles(\n",
    "    row_template='{row_name}',\n",
    "    col_template='{col_name}',\n",
    ")\n",
    "'''ax = sns.boxplot(\n",
    "    tmp_cur_acc_df, hue='Model Type', y='metric_value_test'\n",
    ")'''\n",
    "\n",
    "g.add_legend()\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(0.1, 1.07), ncol=3)\n",
    "\n",
    "for text in g.legend.texts:\n",
    "    if \"GAM\" in text.get_text():\n",
    "        text.set_fontweight(\"bold\")\n",
    "        text.set_color(\"red\")\n",
    "\n",
    "#plt.xticks(rotation=0, ha='center')\n",
    "for ind, ax in enumerate(g.axes.flat):\n",
    "    if ind == 25:\n",
    "        ax.set_ylim(0.86, 0.94)\n",
    "\n",
    "sns.set(font_scale=2.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we grab the runtime comparison figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in model fitting data\n",
    "import pandas as pd\n",
    "dataset_of_interest = ['BREAST_CANCER','FICO','MIMIC', 'PHARYNGITIS', 'CKD', 'HEART_DISEASE']\n",
    "datasets_with_subsamples = []\n",
    "for d in dataset_of_interest:\n",
    "    datasets_with_subsamples = datasets_with_subsamples + [d, f'{d}_0.25', f'{d}_0.5', f'{d}_0.75']\n",
    "main_body_datasets = ['BREAST_CANCER','FICO','MIMIC', 'PHARYNGITIS']\n",
    "imputations_of_interest = ['Mean', 'MICE', 'MIWAE', 'MissForest']\n",
    "target_metric = 'acc'\n",
    "\n",
    "dfs = []\n",
    "for cur_ds in dataset_of_interest:\n",
    "    for ds_name in [cur_ds, f'{cur_ds}_0.25', f'{cur_ds}_0.5', f'{cur_ds}_0.75']:\n",
    "        for imputation_method in imputations_of_interest:\n",
    "            for s_iter in range(120):\n",
    "                try:\n",
    "                    #df = pd.read_csv(f'./parallelized_results/baselines_2024-02_01_iter_{s_iter}_10_imp_all.csv')\n",
    "                    df = pd.read_csv(f'./parallelized_results/baselines_iter_{s_iter}_{ds_name}_{imputation_method}.csv')\n",
    "                    dfs.append(df)\n",
    "                except:\n",
    "                    continue\n",
    "combined_acc_df = pd.concat(dfs, axis=0)\n",
    "\n",
    "df_list = []\n",
    "for ds_name in dataset_of_interest:\n",
    "    for imputation_method in imputations_of_interest:\n",
    "        for subsample in ['', '_0.25', '_0.5', '_0.75']:\n",
    "            try:\n",
    "                df_list.append(pd.read_csv(f'../../handling_missing_data/timing_stats_{ds_name}{subsample}_{imputation_method}_5_3.csv'))\n",
    "            except:\n",
    "                continue\n",
    "base_timing_df = pd.concat(df_list, axis=0)\n",
    "\n",
    "base_timing_df = base_timing_df[(base_timing_df['m'] < 10) & (base_timing_df['imputation'].isin(imputations_of_interest))]\n",
    "\n",
    "mask = (combined_acc_df['num_imputations'] == 10) & (combined_acc_df['metric'] == target_metric)\n",
    "acc_df = combined_acc_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This aggregation should be mean for mean imputations\n",
    "base_timing_df = base_timing_df.groupby(['holdout_set', 'dataset', 'validation_set', 'imputation']).sum().reset_index()\n",
    "#base_timing_df = base_timing_df.groupby(['holdout_set', 'dataset']).mean().reset_index()\n",
    "#base_timing_df\n",
    "#base_timing_df['holdout_set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = acc_df.groupby(['dataset', 'holdout_set', 'model_type']).mean().reset_index()#['holdout_set'].value_counts()\n",
    "\n",
    "merged_df = base_timing_df.merge(acc_df, how='inner', on=['dataset','holdout_set'])\n",
    "\n",
    "# Only MICE actually records a time_overall -- the rest of the imputations\n",
    "# split the time across a few phases. Aggregate those phases for plotting\n",
    "mask = merged_df['time_overall'] == 0\n",
    "merged_df.loc[mask, 'time_overall'] = merged_df.loc[mask, \"time_to_fit\"]\\\n",
    "    + merged_df.loc[mask, \"time_for_train\"]\\\n",
    "    + merged_df.loc[mask, \"time_for_val\"]\\\n",
    "    + merged_df.loc[mask, \"time_for_test\"]\n",
    "\n",
    "# And remove the imputation time from M-GAM rows\n",
    "merged_df['impute_time'] = merged_df['time_overall']\n",
    "\n",
    "mask = (merged_df['model_type'] != 'GAM_ind') & (merged_df['model_type'] != 'GAM_aug')\n",
    "merged_df['overall_time'] = 0\n",
    "merged_df.loc[mask, 'overall_time'] = merged_df.loc[mask, 'impute_time'] + merged_df.loc[mask, 'mean_fit_time']\n",
    "merged_df.loc[~mask, 'overall_time'] = merged_df.loc[~mask,'mean_fit_time']\n",
    "merged_df.loc[~mask, 'impute_time'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[merged_df['model_type'] != 'GAM_no_missing']\n",
    "mask = merged_df['model_type'] == 'GAM_aug'\n",
    "merged_df.loc[mask, 'model_type'] = ' GAM (Interactions)'\n",
    "mask = merged_df['model_type'] == 'GAM_ind'\n",
    "merged_df.loc[mask, 'model_type'] = ' GAM (Indicators)'\n",
    "mask = merged_df['model_type'] == 'GAM_imputation'\n",
    "merged_df.loc[mask, 'model_type'] = ' GAM (Imputation)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df_gam_ind = merged_df[\n",
    "    (merged_df['model_type'] == ' GAM (Indicators)')\n",
    "]\n",
    "\n",
    "merged_df_gam_int = merged_df[\n",
    "    (merged_df['model_type'] == ' GAM (Interactions)')\n",
    "]\n",
    "\n",
    "merged_df_no_gam = merged_df[\n",
    "    ~((merged_df['model_type'] == ' GAM (Imputation)') |\n",
    "    (merged_df['model_type'] == ' GAM (Indicators)') |\n",
    "    (merged_df['model_type'] == ' GAM (Interactions)'))\n",
    "]\n",
    "merged_df_gam_ind.loc[:, 'imputation'] = 'M-GAM (Ind)'\n",
    "merged_df_gam_int.loc[:, 'imputation'] = 'M-GAM (Int)'\n",
    "merged_df_mod = pd.concat((merged_df_no_gam, merged_df_gam_int, merged_df_gam_ind), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dfs = []\n",
    "for imputation in merged_df_mod.imputation.unique():\n",
    "    cur_imp_df = merged_df_mod[merged_df_mod['imputation'] == imputation]\n",
    "    agg_imp_df = cur_imp_df.groupby(\"model_type\").mean().reset_index()\n",
    "    best_model_mean_acc = agg_imp_df['metric_value_test'].max()\n",
    "    target_model = agg_imp_df[agg_imp_df['metric_value_test'] == best_model_mean_acc]['model_type'].values[0]\n",
    "\n",
    "    imp_dfs.append(cur_imp_df[cur_imp_df['model_type'] == target_model])\n",
    "    \n",
    "only_best_model_df = pd.concat(imp_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "df_for_cur_plot = only_best_model_df[only_best_model_df['dataset'].isin(main_body_datasets)]\n",
    "def tweak_dataset_for_sorting(row):\n",
    "    return row['dataset'] + 'z'\n",
    "df_for_cur_plot['sortable_dataset'] = df_for_cur_plot.apply(tweak_dataset_for_sorting, axis=1)\n",
    "df_for_cur_plot = df_for_cur_plot.sort_values(['sortable_dataset', 'imputation'])\n",
    "\n",
    "method_order = ['M-GAM (Ind)', 'M-GAM (Int)', 'Mean', 'MICE', 'MissForest', 'MIWAE']\n",
    "\n",
    "color_pal = sns.color_palette()\n",
    "sns.set(font_scale=2.6)\n",
    "g = sns.FacetGrid(\n",
    "    df_for_cur_plot, \n",
    "    col=\"dataset\", \n",
    "    col_wrap=4, \n",
    "    height=7, \n",
    "    sharey=True,\n",
    "    aspect=1.0)\n",
    "g.map_dataframe(sns.barplot,\n",
    "    y='overall_time',\n",
    "    x='imputation',\n",
    "    order=method_order\n",
    "    #label=\"Model Fit Time\"\n",
    "    #hue='model'\n",
    ").set(yscale ='log')\n",
    "\n",
    "g.set_xticklabels(method_order, rotation=45, ha='right')\n",
    "    \n",
    "g.set_xlabels('')\n",
    "g.set_ylabels('Time (Seconds)')\n",
    "for ax, title in zip(g.axes.flat, [\n",
    "    t.title.get_text().split(\" \")[-1].replace(\"_\", \" \") if \"FICO\" in t.title.get_text() or \"MIMIC\" in t.title.get_text() or \"CKD\" in t.title.get_text() \\\n",
    "    else t.title.get_text().split(\" \")[-1].replace(\"_\", \" \").title() for t in g.axes.flat]):\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "bold_font = FontProperties(weight='bold')\n",
    "for ax in g.axes.flat:\n",
    "    xticklabels = ax.get_xticklabels()\n",
    "    new_labels = []\n",
    "    for lbl in xticklabels:\n",
    "        if \"GAM\" in lbl.get_text():\n",
    "            lbl.set_fontproperties(bold_font)\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Figure 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "df_for_cur_plot = only_best_model_df[only_best_model_df['dataset'].isin(dataset_of_interest)]\n",
    "def tweak_dataset_for_sorting(row):\n",
    "    return row['dataset'] + 'z'\n",
    "df_for_cur_plot['sortable_dataset'] = df_for_cur_plot.apply(tweak_dataset_for_sorting, axis=1)\n",
    "df_for_cur_plot = df_for_cur_plot.sort_values(['sortable_dataset', 'imputation'])\n",
    "\n",
    "method_order = ['M-GAM (Ind)', 'M-GAM (Int)', 'Mean', 'MICE', 'MissForest', 'MIWAE']\n",
    "\n",
    "color_pal = sns.color_palette()\n",
    "sns.set(font_scale=2.6)\n",
    "g = sns.FacetGrid(\n",
    "    df_for_cur_plot, \n",
    "    col=\"dataset\", \n",
    "    col_wrap=3, \n",
    "    height=7, \n",
    "    sharey=True,\n",
    "    aspect=1.0)\n",
    "g.map_dataframe(sns.barplot,\n",
    "    y='overall_time',\n",
    "    x='imputation',\n",
    "    order=method_order\n",
    "    #label=\"Model Fit Time\"\n",
    "    #hue='model'\n",
    ").set(yscale ='log')\n",
    "\n",
    "g.set_xticklabels(method_order, rotation=45, ha='right')\n",
    "    \n",
    "g.set_xlabels('')\n",
    "g.set_ylabels('Time (Seconds)')\n",
    "for ax, title in zip(g.axes.flat, [\n",
    "    t.title.get_text().split(\" \")[-1].replace(\"_\", \" \") if \"FICO\" in t.title.get_text() or \"MIMIC\" in t.title.get_text() or \"CKD\" in t.title.get_text() \\\n",
    "    else t.title.get_text().split(\" \")[-1].replace(\"_\", \" \").title() for t in g.axes.flat]):\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "bold_font = FontProperties(weight='bold')\n",
    "for ax in g.axes.flat:\n",
    "    xticklabels = ax.get_xticklabels()\n",
    "    new_labels = []\n",
    "    for lbl in xticklabels:\n",
    "        if \"GAM\" in lbl.get_text():\n",
    "            lbl.set_fontproperties(bold_font)\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Figure 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "df_for_cur_plot = only_best_model_df\n",
    "def tweak_dataset_for_sorting(row):\n",
    "    return row['dataset'] + 'z'\n",
    "df_for_cur_plot['sortable_dataset'] = df_for_cur_plot.apply(tweak_dataset_for_sorting, axis=1)\n",
    "df_for_cur_plot = df_for_cur_plot.sort_values(['sortable_dataset', 'imputation'])\n",
    "\n",
    "method_order = ['M-GAM (Ind)', 'M-GAM (Int)', 'Mean', 'MICE', 'MissForest', 'MIWAE']\n",
    "\n",
    "color_pal = sns.color_palette()\n",
    "sns.set(font_scale=2.6)\n",
    "g = sns.FacetGrid(\n",
    "    df_for_cur_plot, \n",
    "    col=\"dataset\", \n",
    "    col_wrap=4, \n",
    "    height=7, \n",
    "    sharey=True,\n",
    "    aspect=1.0)\n",
    "g.map_dataframe(sns.barplot,\n",
    "    y='overall_time',\n",
    "    x='imputation',\n",
    "    order=method_order\n",
    "    #label=\"Model Fit Time\"\n",
    "    #hue='model'\n",
    ").set(yscale ='log')\n",
    "\n",
    "g.set_xticklabels(method_order, rotation=45, ha='right')\n",
    "    \n",
    "g.set_xlabels('')\n",
    "g.set_ylabels('Time (Seconds)')\n",
    "for ax, title in zip(g.axes.flat, [\n",
    "    t.title.get_text().split(\" \")[-1].replace(\"_\", \" \") if \"FICO\" in t.title.get_text() or \"MIMIC\" in t.title.get_text() or \"CKD\" in t.title.get_text() \\\n",
    "    else t.title.get_text().split(\" \")[-1].replace(\"_\", \" \").title() for t in g.axes.flat]):\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "bold_font = FontProperties(weight='bold')\n",
    "for ax in g.axes.flat:\n",
    "    xticklabels = ax.get_xticklabels()\n",
    "    new_labels = []\n",
    "    for lbl in xticklabels:\n",
    "        if \"GAM\" in lbl.get_text():\n",
    "            lbl.set_fontproperties(bold_font)\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obj_det_env_2",
   "language": "python",
   "name": "obj_det_env_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
