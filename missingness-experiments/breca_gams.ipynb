{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastsparsegams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input parameters for plots, info about MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_seed=1\n",
    "subset = False #'no_external'#f'Random_seed={subset_seed}'\n",
    "subset_size=5\n",
    "\n",
    "added_missingness_seed = 1\n",
    "added_missingness_num_cols = 1\n",
    "added_missingness_rate = 0.2\n",
    "added_missingness = f'mnar_pro_aug_{added_missingness_num_cols}_random_cols_{added_missingness_rate}_missingness_rate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Breast_cancer_complete_used_onehot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list(df)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now, fill na with -7; later double check to make sure this isn't throwing off our non-intercept experiments\n",
    "df.fillna(-7, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subset: \n",
    "    if 'Random' in subset: \n",
    "        np.random.seed(subset_seed)\n",
    "        cols = df.columns[list(np.random.choice(df.shape[1]-1, 5, replace=False)) + [-1]]\n",
    "        df = df[cols]\n",
    "    elif 'no_external' in subset:\n",
    "        cols = list(set(df.columns) - set(['ExternalRiskEstimate']))\n",
    "        df = df[cols]\n",
    "    else: \n",
    "        df = df[df.columns[[-9, -5, -4, -3, -2, -1]]] #highest missingness prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding missingness to: ER Status of the Primary\n"
     ]
    }
   ],
   "source": [
    "if added_missingness:\n",
    "    np.random.seed(added_missingness_seed)\n",
    "    if 'random_col' in added_missingness:\n",
    "        target_cols = np.random.choice(df.shape[1]-1, added_missingness_num_cols, replace=False)\n",
    "    \n",
    "    if 'mnar_pro_aug' in added_missingness:\n",
    "        inter_cols = np.random.choice(df.shape[1]-1, added_missingness_num_cols, replace=False)\n",
    "        targets = np.random.choice([0, 1], size=(df.shape[0], target_cols.shape[0]), p=[1-added_missingness_rate, added_missingness_rate])\n",
    "        \n",
    "        for i, col in enumerate(target_cols):\n",
    "            print(f\"Adding missingness to: {df.columns[col]}\")\n",
    "            thresh_col = df.columns[inter_cols[i]]\n",
    "            thresh_mask = df[thresh_col] >= df[thresh_col].quantile(0.6)\n",
    "            tartget_labels = np.zeros_like(thresh_mask)\n",
    "            tartget_labels[thresh_mask] = 1\n",
    "            mask = (targets[:, i] == 1) & (df[label] == tartget_labels)\n",
    "            df.loc[mask, df.columns[col]] = -10\n",
    "        \n",
    "    elif 'mnar' in added_missingness:\n",
    "        targets = np.random.choice([0, 1], size=(df.shape[0], target_cols.shape[0]), p=[1-added_missingness_rate, added_missingness_rate])\n",
    "        \n",
    "        for i, col in enumerate(target_cols):\n",
    "            print(f\"Adding missingness to: {df.columns[col]}\")\n",
    "            mask = (targets[:, i] == 1) & (df[label] == 1)\n",
    "            df.loc[mask, df.columns[col]] = -10\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rate for Fraction Genome Altered 0.012528473804100227\n",
      "Missing rate for Invasive Carcinoma Diagnosis Age 0.0\n",
      "Missing rate for Metastatic Recurrence Time 0.28189066059225515\n",
      "Missing rate for Mutation Count 0.044988610478359906\n",
      "Missing rate for Oncotree Code_ACBC 0.0\n",
      "Missing rate for Oncotree Code_BRCA 0.0\n",
      "Missing rate for Oncotree Code_BRCANOS 0.0\n",
      "Missing rate for Oncotree Code_BREAST 0.0\n",
      "Missing rate for Oncotree Code_IDC 0.0\n",
      "Missing rate for Oncotree Code_ILC 0.0\n",
      "Missing rate for Oncotree Code_IMMC 0.0\n",
      "Missing rate for Oncotree Code_MBC 0.0\n",
      "Missing rate for Oncotree Code_MDLC 0.0\n",
      "Missing rate for Overall Patient Receptor Status_HR+/HER2+ 0.0\n",
      "Missing rate for Overall Patient Receptor Status_HR+/HER2- 0.0\n",
      "Missing rate for Overall Patient Receptor Status_HR-/HER2+ 0.0\n",
      "Missing rate for Overall Patient Receptor Status_Triple Negative 0.0\n",
      "Missing rate for ER Status of the Primary 0.1366742596810934\n",
      "Missing rate for Metastatic Disease at Last Follow-up 0.0\n",
      "Missing rate for M Stage 0.0\n",
      "Missing rate for N Stage 0.003416856492027335\n",
      "Missing rate for Overall Patient HER2 Status 0.0\n",
      "Missing rate for Overall Patient HR Status 0.0\n",
      "Missing rate for Overall Primary Tumor Grade 0.09851936218678815\n",
      "Missing rate for PR Status of the Primary 0.022779043280182234\n",
      "Missing rate for Stage At Diagnosis 0.007403189066059226\n",
      "Missing rate for T Stage 0.007403189066059226\n",
      "Missing rate for Overall Survival Status 0.0\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(f\"Missing rate for {c}\", df[df[c] <= -7].shape[0] / df[c].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions for running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_according_to_train(train_df, test_df, overall_mi_intercept = True, overall_mi_ixn = True, specific_mi_intercept = True, specific_mi_ixn = True):\n",
    "    n_train, d_train = train_df.shape\n",
    "    n_test, d_test = test_df.shape\n",
    "    train_binned, train_augmented_binned, test_binned, test_augmented_binned = {}, {}, {}, {}\n",
    "    train_no_missing, test_no_missing = {}, {}\n",
    "    for c in train_df.columns:\n",
    "        if c == label:\n",
    "            continue\n",
    "        missing_col_name = f'{c} missing'\n",
    "        missing_row_train = np.zeros(n_train)\n",
    "        missing_row_test = np.zeros(n_test)\n",
    "        for v in list(train_df[c].quantile([0.2, 0.4, 0.6, 0.8, 1]).unique()) + [-7, -8, -9, 10]:\n",
    "            if v in [-7, -8, -9, -10]:\n",
    "\n",
    "                if specific_mi_intercept:\n",
    "                    new_col_name = f'{c} == {v}'\n",
    "    \n",
    "                    new_row_train = np.zeros(n_train)\n",
    "                    new_row_train[train_df[c] == v] = 1\n",
    "                    train_binned[new_col_name] = new_row_train\n",
    "                    train_augmented_binned[new_col_name] = new_row_train\n",
    "                    \n",
    "                    new_row_test = np.zeros(n_test)\n",
    "                    new_row_test[test_df[c] == v] = 1\n",
    "                    test_binned[new_col_name] = new_row_test\n",
    "                    test_augmented_binned[new_col_name] = new_row_test\n",
    "\n",
    "                missing_row_train[train_df[c] == v] = 1\n",
    "                missing_row_test[test_df[c] == v] = 1\n",
    "            else:\n",
    "                new_col_name = f'{c} <= {v}'\n",
    "\n",
    "                new_row_train = np.zeros(n_train)\n",
    "                new_row_train[train_df[c] <= v] = 1\n",
    "                train_no_missing[new_col_name] = new_row_train\n",
    "                train_binned[new_col_name] = new_row_train\n",
    "                train_augmented_binned[new_col_name] = new_row_train\n",
    "                \n",
    "                new_row_test = np.zeros(n_test)\n",
    "                new_row_test[test_df[c] <= v] = 1\n",
    "                test_no_missing[new_col_name] = new_row_test\n",
    "                test_binned[new_col_name] = new_row_test\n",
    "                test_augmented_binned[new_col_name] = new_row_test\n",
    "\n",
    "        if overall_mi_intercept: \n",
    "            train_binned[missing_col_name] = missing_row_train\n",
    "            train_augmented_binned[missing_col_name] = missing_row_train\n",
    "        \n",
    "            test_binned[missing_col_name] = missing_row_test\n",
    "            test_augmented_binned[missing_col_name] = missing_row_test\n",
    "    \n",
    "    for c_outer in train_df.columns:\n",
    "        if c_outer == label:\n",
    "            continue\n",
    "        for c_inner in train_df.columns:\n",
    "            for v in train_df[c_inner].quantile([0.2, 0.4, 0.6, 0.8, 1]).unique():\n",
    "                if (v in [-7, -8, -9, -10]) or c_inner == label:\n",
    "                    continue\n",
    "                else:\n",
    "                    missing_ixn_name = f'{c_outer} missing & {c_inner} <= {v}'\n",
    "                    missing_ixn_row_train = np.zeros(n_train)\n",
    "                    missing_ixn_row_test = np.zeros(n_test)\n",
    "                    for m_val in [-7, -8, -9, -10]:\n",
    "                        if specific_mi_ixn: \n",
    "                            new_col_name = f'{c_outer}_missing_{m_val} & {c_inner} <= {v}'\n",
    "    \n",
    "                            new_row_train = np.zeros(n_train)\n",
    "                            new_row_train[(train_df[c_outer] == m_val) & (train_df[c_inner] <= v)] = 1\n",
    "                            train_augmented_binned[new_col_name] = new_row_train\n",
    "    \n",
    "                            new_row_test = np.zeros(n_test)\n",
    "                            new_row_test[(test_df[c_outer] == m_val) & (test_df[c_inner] <= v)] = 1\n",
    "                            test_augmented_binned[new_col_name] = new_row_test\n",
    "\n",
    "                        missing_ixn_row_train[(train_df[c_outer] == m_val) & (train_df[c_inner] <= v)] = 1\n",
    "                        missing_ixn_row_test[(test_df[c_outer] == m_val) & (test_df[c_inner] <= v)] = 1\n",
    "\n",
    "                    if overall_mi_ixn: \n",
    "                        train_augmented_binned[missing_ixn_name] = missing_ixn_row_train\n",
    "                        test_augmented_binned[missing_ixn_name] = missing_ixn_row_test\n",
    "                        \n",
    "    train_binned[label] = train_df[label]\n",
    "    test_binned[label] = test_df[label]\n",
    "    train_no_missing[label] = train_df[label]\n",
    "    test_no_missing[label] = test_df[label]\n",
    "    train_augmented_binned[label] = train_df[label]\n",
    "    test_augmented_binned[label] = test_df[label]\n",
    "    return pd.DataFrame(train_no_missing), pd.DataFrame(train_binned), pd.DataFrame(train_augmented_binned), \\\n",
    "         pd.DataFrame(test_no_missing), pd.DataFrame(test_binned), pd.DataFrame(test_augmented_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recover coefficients and train/test probabilities\n",
    "def eval_model(model, X_train, X_test, col_names): \n",
    "    coeffs = np.zeros((len(model.lambda_0[0]), X_train.shape[1]))\n",
    "    missing_coeffs = np.zeros((len(model.lambda_0[0])))\n",
    "    inter_coeffs = np.zeros((len(model.lambda_0[0])))\n",
    "    train_probs = np.zeros((len(model.lambda_0[0]), X_train.shape[0]))\n",
    "    test_probs = np.zeros((len(model.lambda_0[0]), X_test.shape[0]))\n",
    "\n",
    "    for i, lamby in enumerate(model.lambda_0[0]): \n",
    "        train_probs[i] = model.predict(X_train.astype(float),lambda_0=lamby).reshape(-1)\n",
    "        test_probs[i] = model.predict(X_test.astype(float),lambda_0=lamby).reshape(-1)\n",
    "\n",
    "        cur_col_names = col_names[(model.coeff(lambda_0=lamby).toarray().flatten()[1:] != 0)]\n",
    "        missing_coeffs[i] = sum(['-' in c for c in cur_col_names])\n",
    "        inter_coeffs[i] = sum(['&' in c for c in cur_col_names])\n",
    "        coeffs[i] = (model.coeff(lambda_0=lamby).toarray().flatten())[1:] #first entry is intercept\n",
    "    return train_probs, test_probs, coeffs, missing_coeffs, inter_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(num_trials, 2, figsize=(20, 30))\n",
    "\n",
    "# plt.suptitle(\"Train/Test accuracy for each fold\")\n",
    "\n",
    "for idx in range(0, num_trials): \n",
    "    print(idx)\n",
    "\n",
    "    # set up train/test sets for our 3 settings: no missingness, missingness intercept, missingness interaction\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=idx, stratify=df[label])\n",
    "    train_no_missing, train_binned, train_binned_augmented, test_no_missing, test_binned, test_binned_augmented = binarize_according_to_train(train_df, test_df)\n",
    "    X_indicator_train = train_binned[train_binned.columns[:-1]].values\n",
    "    y_train = train_binned[label].values\n",
    "    X_indicator_test = test_binned[test_binned.columns[:-1]].values\n",
    "    y_test = test_binned[label].values\n",
    "    X_no_missing_train = train_no_missing[train_no_missing.columns[:-1]].values\n",
    "    X_no_missing_test = test_no_missing[test_no_missing.columns[:-1]].values\n",
    "    X_aug_train = train_binned_augmented[train_binned_augmented.columns[:-1]].values\n",
    "    X_aug_test = test_binned_augmented[test_binned_augmented.columns[:-1]].values\n",
    "\n",
    "    # run fastsparse on these 3 datasets\n",
    "    model_aug = fastsparsegams.fit(X_aug_train.astype(float), y_train.astype(int)*2 - 1, loss=\"Exponential\", max_support_size=40, algorithm=\"CDPSI\")\n",
    "    model_indicator = fastsparsegams.fit(X_indicator_train.astype(float), y_train.astype(int)*2 - 1, loss=\"Exponential\", max_support_size=40, algorithm=\"CDPSI\")\n",
    "    model_no_missing = fastsparsegams.fit(X_no_missing_train.astype(float), y_train.astype(int)*2 - 1, loss=\"Exponential\", max_support_size=40, algorithm=\"CDPSI\")\n",
    "\n",
    "    # evaluate models\n",
    "    train_probs_aug, test_probs_aug, coeff_aug, missing_coeff_aug, inter_coeffs = eval_model(model_aug, X_aug_train, \n",
    "                                                                            X_aug_test, train_binned_augmented.columns[:-1])\n",
    "    trainacc_aug = ((train_probs_aug > 0.5) == y_train).mean(axis = 1)\n",
    "    testacc_aug = ((test_probs_aug > 0.5) == y_test).mean(axis = 1)\n",
    "    num_terms_aug = (coeff_aug != 0).sum(axis=1)\n",
    "\n",
    "    train_probs_indicator, test_probs_indicator, coeff_indicator, missing_coeff_indicator, _ = eval_model(model_indicator, \n",
    "                                                                                                    X_indicator_train, \n",
    "                                                                                                    X_indicator_test,\n",
    "                                                                                                    train_binned.columns[:-1])\n",
    "    trainacc_indicator = ((train_probs_indicator > 0.5) == y_train).mean(axis=1)\n",
    "    testacc_indicator = ((test_probs_indicator > 0.5) == y_test).mean(axis=1)\n",
    "    num_terms_indicator = (coeff_indicator != 0).sum(axis=1)\n",
    "\n",
    "    train_probs_no_missing, test_probs_no_missing, coeff_no_missing, missing_coeff_no_missing, _ = eval_model(model_no_missing, X_no_missing_train, X_no_missing_test, train_no_missing.columns[:-1])\n",
    "    trainacc_no_missing = ((train_probs_no_missing > 0.5) == y_train).mean(axis=1)\n",
    "    testacc_no_missing = ((test_probs_no_missing > 0.5) == y_test).mean(axis=1)\n",
    "    num_terms_no_missing = (coeff_no_missing != 0).sum(axis=1)\n",
    "    \n",
    "    ax = axs[idx, 0]\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    ax.set_title('Train Accuracy vs # Nonzero Coefficients')#\\n (Other than intercept)\n",
    "    ax.plot(num_terms_no_missing[num_terms_no_missing > 0], trainacc_no_missing[num_terms_no_missing > 0], label='train accuracy, no missing')\n",
    "    ax.plot(num_terms_aug[num_terms_aug > 0], trainacc_aug[num_terms_aug > 0], label='train accuracy, interaction')\n",
    "    ax.plot(num_terms_indicator[num_terms_indicator > 0], trainacc_indicator[num_terms_indicator > 0], label='train accuracy, only indicator')\n",
    "    ax.set_ylabel('Classification Accuracy')\n",
    "    ax.set_xlabel('# Nonzero coefficients')\n",
    "    ax.set_ylim([0.55, max(0.8, max(trainacc_aug))])\n",
    "    ax.legend(['No missing', 'Augmented', 'Indicator'])\n",
    "\n",
    "    ax = axs[idx, 1]\n",
    "\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_title('Test Accuracy vs # Nonzero Coefficients')#\\n (Other than intercept)\n",
    "    ax.plot(num_terms_no_missing[num_terms_no_missing > 0], testacc_no_missing[num_terms_no_missing > 0], label='test accuracy, no missing')\n",
    "    ax.plot(num_terms_aug[num_terms_aug > 0], testacc_aug[num_terms_aug > 0], label='test accuracy, interaction')\n",
    "    ax.plot(num_terms_indicator[num_terms_indicator > 0], testacc_indicator[num_terms_indicator > 0], label='test accuracy, only indicator')\n",
    "    ax.set_ylabel('Classification Accuracy')\n",
    "    ax.set_xlabel('# Nonzero coefficients')\n",
    "    ax.set_ylim([0.55, max(0.8, max(testacc_aug))])\n",
    "    ax.legend(['No missing', 'Augmented', 'Indicator'])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# plt.savefig(f'figs/Nov/train_test_additive_missingness_subset={subset}_added_missingness={added_missingness}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'figs/Dec/breca_train_test_additive_missingness_subset={subset}_added_missingness={added_missingness}'\n",
    "plt.savefig(f'{filename}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{filename}.txt', 'w') as outfile: \n",
    "    for c in df.columns:\n",
    "        outfile.write(f\"Missing rate for {c}\" + str(df[df[c] <= -7].shape[0] / df[c].shape[0]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
