{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastsparsegams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input parameters for plots, info about MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_seed=1\n",
    "subset = False #'no_external'#f'Random_seed={subset_seed}'\n",
    "subset_size=5\n",
    "\n",
    "added_missingness_seed = 1\n",
    "added_missingness_num_cols = 1\n",
    "added_missingness_rate = 0.2\n",
    "added_missingness = f'mnar_pro_aug_{added_missingness_num_cols}_random_cols_{added_missingness_rate}_missingness_rate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./fico_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subset: \n",
    "    if 'Random' in subset: \n",
    "        np.random.seed(subset_seed)\n",
    "        cols = df.columns[list(np.random.choice(df.shape[1]-1, 5, replace=False)) + [-1]]\n",
    "        df = df[cols]\n",
    "    elif 'no_external' in subset:\n",
    "        cols = list(set(df.columns) - set(['ExternalRiskEstimate']))\n",
    "        df = df[cols]\n",
    "    else: \n",
    "        df = df[df.columns[[-9, -5, -4, -3, -2, -1]]] #highest missingness prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding missingness to: NumRevolvingTradesWBalance\n"
     ]
    }
   ],
   "source": [
    "if added_missingness:\n",
    "    np.random.seed(added_missingness_seed)\n",
    "    if 'random_col' in added_missingness:\n",
    "        target_cols = np.random.choice(df.shape[1]-1, added_missingness_num_cols, replace=False)\n",
    "    \n",
    "    if 'mnar_pro_aug' in added_missingness:\n",
    "        inter_cols = np.random.choice(df.shape[1]-1, added_missingness_num_cols, replace=False)\n",
    "        targets = np.random.choice([0, 1], size=(df.shape[0], target_cols.shape[0]), p=[1-added_missingness_rate, added_missingness_rate])\n",
    "        \n",
    "        for i, col in enumerate(target_cols):\n",
    "            print(f\"Adding missingness to: {df.columns[col]}\")\n",
    "            thresh_col = df.columns[inter_cols[i]]\n",
    "            thresh_mask = df[thresh_col] >= df[thresh_col].quantile(0.6)\n",
    "            tartget_labels = np.zeros_like(thresh_mask)\n",
    "            tartget_labels[thresh_mask] = 1\n",
    "            mask = (targets[:, i] == 1) & (df['PoorRiskPerformance'] == tartget_labels)\n",
    "            df.loc[mask, df.columns[col]] = -10\n",
    "        \n",
    "    elif 'mnar' in added_missingness:\n",
    "        targets = np.random.choice([0, 1], size=(df.shape[0], target_cols.shape[0]), p=[1-added_missingness_rate, added_missingness_rate])\n",
    "        \n",
    "        for i, col in enumerate(target_cols):\n",
    "            print(f\"Adding missingness to: {df.columns[col]}\")\n",
    "            mask = (targets[:, i] == 1) & (df['PoorRiskPerformance'] == 1)\n",
    "            df.loc[mask, df.columns[col]] = -10\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        20\n",
       "1         2\n",
       "2         9\n",
       "3        28\n",
       "4        12\n",
       "         ..\n",
       "10454    21\n",
       "10455    11\n",
       "10456    18\n",
       "10457    42\n",
       "10458     4\n",
       "Name: NumSatisfactoryTrades, Length: 10459, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NumSatisfactoryTrades']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rate for PercentTradesWBalance 0.057940529687350605\n",
      "Missing rate for ExternalRiskEstimate 0.057175638206329475\n",
      "Missing rate for MSinceOldestTradeOpen 0.07907065685055932\n",
      "Missing rate for MSinceMostRecentTradeOpen 0.056219523855053063\n",
      "Missing rate for AverageMInFile 0.056219523855053063\n",
      "Missing rate for NumSatisfactoryTrades 0.056219523855053063\n",
      "Missing rate for NumTrades60Ever2DerogPubRec 0.056219523855053063\n",
      "Missing rate for NumTrades90Ever2DerogPubRec 0.056219523855053063\n",
      "Missing rate for PercentTradesNeverDelq 0.056219523855053063\n",
      "Missing rate for MSinceMostRecentDelq 0.5189788698728368\n",
      "Missing rate for MaxDelq2PublicRecLast12M 0.056219523855053063\n",
      "Missing rate for MaxDelqEver 0.056219523855053063\n",
      "Missing rate for NumTotalTrades 0.056219523855053063\n",
      "Missing rate for NumTradesOpeninLast12M 0.056219523855053063\n",
      "Missing rate for PercentInstallTrades 0.056219523855053063\n",
      "Missing rate for MSinceMostRecentInqexcl7days 0.27908977913758487\n",
      "Missing rate for NumInqLast6M 0.056219523855053063\n",
      "Missing rate for NumInqLast6Mexcl7days 0.056219523855053063\n",
      "Missing rate for NetFractionRevolvingBurden 0.07400325078879434\n",
      "Missing rate for NetFractionInstallBurden 0.3831150205564586\n",
      "Missing rate for NumRevolvingTradesWBalance 0.15842814800650157\n",
      "Missing rate for NumInstallTradesWBalance 0.1385409694999522\n",
      "Missing rate for NumBank2NatlTradesWHighUtilization 0.11196099053446792\n",
      "Missing rate for PoorRiskPerformance 0.0\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(f\"Missing rate for {c}\", df[df[c] <= -7].shape[0] / df[c].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions for running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_according_to_train(train_df, test_df, overall_mi_intercept = True, overall_mi_ixn = True, specific_mi_intercept = True, specific_mi_ixn = True):\n",
    "    n_train, d_train = train_df.shape\n",
    "    n_test, d_test = test_df.shape\n",
    "    train_binned, train_augmented_binned, test_binned, test_augmented_binned = {}, {}, {}, {}\n",
    "    train_no_missing, test_no_missing = {}, {}\n",
    "    for c in train_df.columns:\n",
    "        if c == 'PoorRiskPerformance':\n",
    "            continue\n",
    "        missing_col_name = f'{c} missing'\n",
    "        missing_row_train = np.zeros(n_train)\n",
    "        missing_row_test = np.zeros(n_test)\n",
    "        for v in list(train_df[c].quantile([0.2, 0.4, 0.6, 0.8, 1]).unique()) + [-7, -8, -9, 10]:\n",
    "            if v in [-7, -8, -9, -10]:\n",
    "\n",
    "                if specific_mi_intercept:\n",
    "                    new_col_name = f'{c} == {v}'\n",
    "    \n",
    "                    new_row_train = np.zeros(n_train)\n",
    "                    new_row_train[train_df[c] == v] = 1\n",
    "                    train_binned[new_col_name] = new_row_train\n",
    "                    train_augmented_binned[new_col_name] = new_row_train\n",
    "                    \n",
    "                    new_row_test = np.zeros(n_test)\n",
    "                    new_row_test[test_df[c] == v] = 1\n",
    "                    test_binned[new_col_name] = new_row_test\n",
    "                    test_augmented_binned[new_col_name] = new_row_test\n",
    "\n",
    "                missing_row_train[train_df[c] == v] = 1\n",
    "                missing_row_test[test_df[c] == v] = 1\n",
    "            else:\n",
    "                new_col_name = f'{c} <= {v}'\n",
    "\n",
    "                new_row_train = np.zeros(n_train)\n",
    "                new_row_train[train_df[c] <= v] = 1\n",
    "                train_no_missing[new_col_name] = new_row_train\n",
    "                train_binned[new_col_name] = new_row_train\n",
    "                train_augmented_binned[new_col_name] = new_row_train\n",
    "                \n",
    "                new_row_test = np.zeros(n_test)\n",
    "                new_row_test[test_df[c] <= v] = 1\n",
    "                test_no_missing[new_col_name] = new_row_test\n",
    "                test_binned[new_col_name] = new_row_test\n",
    "                test_augmented_binned[new_col_name] = new_row_test\n",
    "\n",
    "        if overall_mi_intercept: \n",
    "            train_binned[missing_col_name] = missing_row_train\n",
    "            train_augmented_binned[missing_col_name] = missing_row_train\n",
    "        \n",
    "            test_binned[missing_col_name] = missing_row_test\n",
    "            test_augmented_binned[missing_col_name] = missing_row_test\n",
    "    \n",
    "    for c_outer in train_df.columns:\n",
    "        if c_outer == 'PoorRiskPerformance':\n",
    "            continue\n",
    "        for c_inner in train_df.columns:\n",
    "            for v in train_df[c_inner].quantile([0.2, 0.4, 0.6, 0.8, 1]).unique():\n",
    "                if (v in [-7, -8, -9, -10]) or c_inner == 'PoorRiskPerformance':\n",
    "                    continue\n",
    "                else:\n",
    "                    missing_ixn_name = f'{c_outer} missing & {c_inner} <= {v}'\n",
    "                    missing_ixn_row_train = np.zeros(n_train)\n",
    "                    missing_ixn_row_test = np.zeros(n_test)\n",
    "                    for m_val in [-7, -8, -9, -10]:\n",
    "                        if specific_mi_ixn: \n",
    "                            new_col_name = f'{c_outer}_missing_{m_val} & {c_inner} <= {v}'\n",
    "    \n",
    "                            new_row_train = np.zeros(n_train)\n",
    "                            new_row_train[(train_df[c_outer] == m_val) & (train_df[c_inner] <= v)] = 1\n",
    "                            train_augmented_binned[new_col_name] = new_row_train\n",
    "    \n",
    "                            new_row_test = np.zeros(n_test)\n",
    "                            new_row_test[(test_df[c_outer] == m_val) & (test_df[c_inner] <= v)] = 1\n",
    "                            test_augmented_binned[new_col_name] = new_row_test\n",
    "\n",
    "                        missing_ixn_row_train[(train_df[c_outer] == m_val) & (train_df[c_inner] <= v)] = 1\n",
    "                        missing_ixn_row_test[(test_df[c_outer] == m_val) & (test_df[c_inner] <= v)] = 1\n",
    "\n",
    "                    if overall_mi_ixn: \n",
    "                        train_augmented_binned[missing_ixn_name] = missing_ixn_row_train\n",
    "                        test_augmented_binned[missing_ixn_name] = missing_ixn_row_test\n",
    "                        \n",
    "    train_binned['PoorRiskPerformance'] = train_df['PoorRiskPerformance']\n",
    "    test_binned['PoorRiskPerformance'] = test_df['PoorRiskPerformance']\n",
    "    train_no_missing['PoorRiskPerformance'] = train_df['PoorRiskPerformance']\n",
    "    test_no_missing['PoorRiskPerformance'] = test_df['PoorRiskPerformance']\n",
    "    train_augmented_binned['PoorRiskPerformance'] = train_df['PoorRiskPerformance']\n",
    "    test_augmented_binned['PoorRiskPerformance'] = test_df['PoorRiskPerformance']\n",
    "    return pd.DataFrame(train_no_missing), pd.DataFrame(train_binned), pd.DataFrame(train_augmented_binned), \\\n",
    "         pd.DataFrame(test_no_missing), pd.DataFrame(test_binned), pd.DataFrame(test_augmented_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recover coefficients and train/test probabilities\n",
    "def eval_model(model, X_train, X_test, col_names): \n",
    "    coeffs = np.zeros((len(model.lambda_0[0]), X_train.shape[1]))\n",
    "    missing_coeffs = np.zeros((len(model.lambda_0[0])))\n",
    "    inter_coeffs = np.zeros((len(model.lambda_0[0])))\n",
    "    train_probs = np.zeros((len(model.lambda_0[0]), X_train.shape[0]))\n",
    "    test_probs = np.zeros((len(model.lambda_0[0]), X_test.shape[0]))\n",
    "\n",
    "    for i, lamby in enumerate(model.lambda_0[0]): \n",
    "        train_probs[i] = model.predict(X_train.astype(float),lambda_0=lamby).reshape(-1)\n",
    "        test_probs[i] = model.predict(X_test.astype(float),lambda_0=lamby).reshape(-1)\n",
    "\n",
    "        cur_col_names = col_names[(model.coeff(lambda_0=lamby).toarray().flatten()[1:] != 0)]\n",
    "        missing_coeffs[i] = sum(['-' in c for c in cur_col_names])\n",
    "        inter_coeffs[i] = sum(['&' in c for c in cur_col_names])\n",
    "        coeffs[i] = (model.coeff(lambda_0=lamby).toarray().flatten())[1:] #first entry is intercept\n",
    "    return train_probs, test_probs, coeffs, missing_coeffs, inter_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(num_trials, 2, figsize=(20, 30))\n",
    "\n",
    "# plt.suptitle(\"Train/Test accuracy for each fold\")\n",
    "\n",
    "for idx in range(0, num_trials): \n",
    "    print(idx)\n",
    "\n",
    "    # set up train/test sets for our 3 settings: no missingness, missingness intercept, missingness interaction\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=idx, stratify=df['PoorRiskPerformance'])\n",
    "    train_no_missing, train_binned, train_binned_augmented, test_no_missing, test_binned, test_binned_augmented = binarize_according_to_train(train_df, test_df)\n",
    "    X_indicator_train = train_binned[train_binned.columns[:-1]].values\n",
    "    y_train = train_binned['PoorRiskPerformance'].values\n",
    "    X_indicator_test = test_binned[test_binned.columns[:-1]].values\n",
    "    y_test = test_binned['PoorRiskPerformance'].values\n",
    "    X_no_missing_train = train_no_missing[train_no_missing.columns[:-1]].values\n",
    "    X_no_missing_test = test_no_missing[test_no_missing.columns[:-1]].values\n",
    "    X_aug_train = train_binned_augmented[train_binned_augmented.columns[:-1]].values\n",
    "    X_aug_test = test_binned_augmented[test_binned_augmented.columns[:-1]].values\n",
    "\n",
    "    # run fastsparse on these 3 datasets\n",
    "    model_aug = fastsparsegams.fit(X_aug_train.astype(float), y_train.astype(int)*2 - 1, loss=\"Exponential\", max_support_size=40, algorithm=\"CDPSI\")\n",
    "    model_indicator = fastsparsegams.fit(X_indicator_train.astype(float), y_train.astype(int)*2 - 1, loss=\"Exponential\", max_support_size=40, algorithm=\"CDPSI\")\n",
    "    model_no_missing = fastsparsegams.fit(X_no_missing_train.astype(float), y_train.astype(int)*2 - 1, loss=\"Exponential\", max_support_size=40, algorithm=\"CDPSI\")\n",
    "\n",
    "    # evaluate models\n",
    "    train_probs_aug, test_probs_aug, coeff_aug, missing_coeff_aug, inter_coeffs = eval_model(model_aug, X_aug_train, \n",
    "                                                                            X_aug_test, train_binned_augmented.columns[:-1])\n",
    "    trainacc_aug = ((train_probs_aug > 0.5) == y_train).mean(axis = 1)\n",
    "    testacc_aug = ((test_probs_aug > 0.5) == y_test).mean(axis = 1)\n",
    "    num_terms_aug = (coeff_aug != 0).sum(axis=1)\n",
    "\n",
    "    train_probs_indicator, test_probs_indicator, coeff_indicator, missing_coeff_indicator, _ = eval_model(model_indicator, \n",
    "                                                                                                    X_indicator_train, \n",
    "                                                                                                    X_indicator_test,\n",
    "                                                                                                    train_binned.columns[:-1])\n",
    "    trainacc_indicator = ((train_probs_indicator > 0.5) == y_train).mean(axis=1)\n",
    "    testacc_indicator = ((test_probs_indicator > 0.5) == y_test).mean(axis=1)\n",
    "    num_terms_indicator = (coeff_indicator != 0).sum(axis=1)\n",
    "\n",
    "    train_probs_no_missing, test_probs_no_missing, coeff_no_missing, missing_coeff_no_missing, _ = eval_model(model_no_missing, X_no_missing_train, X_no_missing_test, train_no_missing.columns[:-1])\n",
    "    trainacc_no_missing = ((train_probs_no_missing > 0.5) == y_train).mean(axis=1)\n",
    "    testacc_no_missing = ((test_probs_no_missing > 0.5) == y_test).mean(axis=1)\n",
    "    num_terms_no_missing = (coeff_no_missing != 0).sum(axis=1)\n",
    "    \n",
    "    ax = axs[idx, 0]\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    ax.set_title('Train Accuracy vs # Nonzero Coefficients')#\\n (Other than intercept)\n",
    "    ax.plot(num_terms_no_missing[num_terms_no_missing > 0], trainacc_no_missing[num_terms_no_missing > 0], label='train accuracy, no missing')\n",
    "    ax.plot(num_terms_aug[num_terms_aug > 0], trainacc_aug[num_terms_aug > 0], label='train accuracy, interaction')\n",
    "    ax.plot(num_terms_indicator[num_terms_indicator > 0], trainacc_indicator[num_terms_indicator > 0], label='train accuracy, only indicator')\n",
    "    ax.set_ylabel('Classification Accuracy')\n",
    "    ax.set_xlabel('# Nonzero coefficients')\n",
    "    ax.set_ylim([0.55, max(0.8, max(trainacc_aug))])\n",
    "    ax.legend(['No missing', 'Augmented', 'Indicator'])\n",
    "\n",
    "    ax = axs[idx, 1]\n",
    "\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_title('Test Accuracy vs # Nonzero Coefficients')#\\n (Other than intercept)\n",
    "    ax.plot(num_terms_no_missing[num_terms_no_missing > 0], testacc_no_missing[num_terms_no_missing > 0], label='test accuracy, no missing')\n",
    "    ax.plot(num_terms_aug[num_terms_aug > 0], testacc_aug[num_terms_aug > 0], label='test accuracy, interaction')\n",
    "    ax.plot(num_terms_indicator[num_terms_indicator > 0], testacc_indicator[num_terms_indicator > 0], label='test accuracy, only indicator')\n",
    "    ax.set_ylabel('Classification Accuracy')\n",
    "    ax.set_xlabel('# Nonzero coefficients')\n",
    "    ax.set_ylim([0.55, max(0.8, max(testacc_aug))])\n",
    "    ax.legend(['No missing', 'Augmented', 'Indicator'])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(f'figs/Nov/train_test_additive_missingness_subset={subset}_added_missingness={added_missingness}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'figs/Nov/train_test_additive_missingness_subset={subset}_added_missingness={added_missingness}.txt', 'w') as outfile: \n",
    "    for c in df.columns:\n",
    "        outfile.write(f\"Missing rate for {c}\" + str(df[df[c] <= -7].shape[0] / df[c].shape[0]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "missing_data",
   "language": "python",
   "name": "missing_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
