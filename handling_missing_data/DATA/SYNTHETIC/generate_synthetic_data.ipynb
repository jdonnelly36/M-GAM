{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating and splitting a synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 1000\n",
    "N_FEATURES = 25\n",
    "N_INFORMATIVE = 25\n",
    "outdir = Path(f'SYNTHETIC_{N_SAMPLES}_SAMPLES_{N_FEATURES}_FEATURES_{N_INFORMATIVE}_INFORMATIVE')\n",
    "outdir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(\n",
    "    n_samples=N_SAMPLES,\n",
    "    n_features=N_FEATURES,\n",
    "    n_informative=N_FEATURES,\n",
    "    n_redundant=0,\n",
    "    random_state=1234\n",
    ")\n",
    "          \n",
    "features_df = pd.DataFrame(x)\n",
    "output_df = pd.DataFrame(y, columns=['output'])\n",
    "data_df = pd.concat([features_df, output_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a copy of the complete dataset for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(outdir / 'synthetic_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test sets with completely at random missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_sampler(p, rows, cols):\n",
    "    np.random.seed(6289278)\n",
    "    unif_random_matrix = np.random.uniform(0., 1., size = (rows, cols))\n",
    "    binary_random_matrix = 1 * (unif_random_matrix < p)\n",
    "    return binary_random_matrix\n",
    "\n",
    "\n",
    "def make_missing_mcar(data_df, miss_rate=0.25, outcome_column='output'):\n",
    "    data_features = data_df.drop(columns=[outcome_column])\n",
    "    data_features_arr = np.array(data_features)\n",
    "\n",
    "    n_rows, n_cols = data_features_arr.shape\n",
    "\n",
    "    data_features_mask = binary_sampler(1 - miss_rate, n_rows, n_cols)\n",
    "    miss_data_features_arr = data_features_arr.copy()\n",
    "    miss_data_features_arr[data_features_mask == 0] = np.nan\n",
    "\n",
    "    miss_data_features = pd.DataFrame(miss_data_features_arr)\n",
    "    outcome = pd.DataFrame(data_df[outcome_column].reset_index(drop=True))\n",
    "    \n",
    "    miss_data = pd.concat([miss_data_features, outcome], axis=1)\n",
    "\n",
    "    return miss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 3\n",
    "n_folds = 5\n",
    "idx = np.arange(len(data_df))\n",
    "\n",
    "kf_splits = KFold(n_splits=n_splits, random_state=1896, shuffle=True)\n",
    "\n",
    "for holdout_num, out_split in enumerate(kf_splits.split(idx)):\n",
    "    idx_train = idx[out_split[0]]\n",
    "    idx_test = idx[out_split[1]]\n",
    "    devel_fold = data_df.iloc[idx_train, ]\n",
    "    test_fold = data_df.iloc[idx_test, ]\n",
    "\n",
    "    for train_percentage in [0,0.25,0.50]:\n",
    "        for test_percentage in [0,0.25,0.50]:\n",
    "            percent_str = f'train_missing_{train_percentage}_test_missing_{test_percentage}'\n",
    "            train_data = make_missing_mcar(devel_fold, train_percentage)\n",
    "            test_data  = make_missing_mcar(test_fold, test_percentage)\n",
    "\n",
    "            test_data.to_csv(outdir / f'holdout_{holdout_num}_{percent_str}.csv', index=False)\n",
    "\n",
    "            kf_folds = KFold(n_splits=n_folds, random_state=165782 * holdout_num, shuffle=True)\n",
    "            idx_folds = np.arange(len(train_data))\n",
    "            for fold_num, idx_fold_split in enumerate(kf_folds.split(idx_folds)):\n",
    "                train_fold = train_data.iloc[idx_fold_split[0]]\n",
    "                val_fold = train_data.iloc[idx_fold_split[1]]\n",
    "                train_fold.to_csv(outdir / f'devel_{holdout_num}_train_{fold_num}_{percent_str}.csv', index=False)\n",
    "                val_fold.to_csv(outdir / f'devel_{holdout_num}_val_{fold_num}_{percent_str}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (imputation-venv)",
   "language": "python",
   "name": "imputation-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
